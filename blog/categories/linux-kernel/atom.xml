<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux-kernel | ykrocku]]></title>
  <link href="http://ykrocku.github.io/blog/categories/linux-kernel/atom.xml" rel="self"/>
  <link href="http://ykrocku.github.io/"/>
  <updated>2014-04-23T15:53:08+08:00</updated>
  <id>http://ykrocku.github.io/</id>
  <author>
    <name><![CDATA[ykrocku]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Unwind_frame函数导致内核内存访问错误]]></title>
    <link href="http://ykrocku.github.io/blog/2014/04/23/unwind-frame-cause-a-kernel-paging-error/"/>
    <updated>2014-04-23T13:43:06+08:00</updated>
    <id>http://ykrocku.github.io/blog/2014/04/23/unwind-frame-cause-a-kernel-paging-error</id>
    <content type="html"><![CDATA[<h2>环境</h2>

<ul>
<li>内核版本： 3.0.8</li>
<li>CPU信息：
```

<h1>cat /proc/cpuinfo</h1>

<p>Processor       : ARMv7 Processor rev 0 (v7l)
processor       : 0
BogoMIPS        : 1849.75</p></li>
</ul>


<p>processor       : 1
BogoMIPS        : 1856.30</p>

<p>Features        : swp half thumb fastmult vfp edsp vfpv3 vfpv3d16
CPU implementer : 0x41
CPU architecture: 7
CPU variant     : 0x3
CPU part        : 0xc09
CPU revision    : 0
```</p>

<h2>问题</h2>

<p>2013年8月份的时候，在一些板子(海思3531平台)上面出现了一些奇怪的问题，查看dmesg都出现了如下打印：
<code>
[283986.090810] Unable to handle kernel paging request at virtual address fffffff3
[283986.090844] pgd = 848b0000
[283986.090855] [fffffff3] *pgd=8cdfe821, *pte=00000000, *ppte=00000000
[283986.090878] Internal error: Oops: 17 [#1] SMP
[283986.090891] Modules linked in: option usb_wwan usbserial hi_ir 8192cu nvp1918 buzzer led regpro debugs_drv ds3231 0104 msdos vfat fat configfs raid1 md_mod sg sr_mod
m ahci_sys libahci sd_mod libata scsi_wait_scan scsi_mod hi3531_adec(P) hi3531_aenc(P) hi3531_ao(P) hi3531_ai(P) hi3531_sio(P) hidmac jpeg hi3531_hdmi(P) hi3531_vfmw(P) h
_vda(P) hi3531_ive(P) hi3531_region(P) hi3531_vpss(P) hi3531_vou(P) hi3531_viu(P) hi3531_mpeg4e(P) hi3531_jpege(P) hi3531_rc(P) hi3531_h264e(P) hi3531_chnl(P) hi3531_grou
(P) hi3531_tde hi3531_sys hi3531_base(P) mmz pca955_driver i2c_module stmmac
[283986.091116] CPU: 0    Tainted: P             (3.0.8 #1)
[283986.091148] PC is at unwind_frame+0x48/0x68
[283986.091163] LR is at get_wchan+0x8c/0x298
[283986.091178] pc : [&lt;8003d120&gt;]    lr : [&lt;8003a660&gt;]    psr: a0000013
[283986.091183] sp : 824dbcc8  ip : 00000003  fp : 824dbcd4
[283986.091204] r10: 00000001  r9 : 00000000  r8 : 80493c34
[283986.091219] r7 : 00000000  r6 : 00000000  r5 : 8b64df40  r4 : 824dbcd8
[283986.091235] r3 : 824dbcd8  r2 : ffffffff  r1 : 80490000  r0 : 8049003f
[283986.091252] Flags: NzCv  IRQs on  FIQs on  Mode SVC_32  ISA ARM  Segment user
[283986.091271] Control: 10c53c7d  Table: 848b004a  DAC: 00000015
[283986.091285]
----cuted----
[283986.094045] Process pidof (pid: 18711, stack limit = 0x824da2f0)
[283986.09[283986.094663]
----cuted----
Backtrace:
[283986.094685] [&lt;8003d0d8&gt;] (unwind_frame+0x0/0x68) from [&lt;8003a660&gt;] (get_wchan+0x8c/0x298)
[283986.094714] [&lt;8003a5d4&gt;] (get_wchan+0x0/0x298) from [&lt;8011f700&gt;] (do_task_stat+0x548/0x5ec)
[283986.094733]  r4:00000000
[283986.094750] [&lt;8011f1b8&gt;] (do_task_stat+0x0/0x5ec) from [&lt;8011f7c0&gt;] (proc_tgid_stat+0x1c/0x24)
[283986.094787] [&lt;8011f7a4&gt;] (proc_tgid_stat+0x0/0x24) from [&lt;8011b7f0&gt;] (proc_single_show+0x54/0x98)
[283986.094823] [&lt;8011b79c&gt;] (proc_single_show+0x0/0x98) from [&lt;800e9024&gt;] (seq_read+0x1b4/0x4e4)
[283986.094842]  r8:824dbf08 r7:824dbf70 r6:00000001 r5:8673bbe0 r4:86c88120
[283986.094864] r3:00000000
[283986.094888] [&lt;800e8e70&gt;] (seq_read+0x0/0x4e4) from [&lt;800c8c54&gt;] (vfs_read+0xb4/0x19c)
[283986.094913] [&lt;800c8ba0&gt;] (vfs_read+0x0/0x19c) from [&lt;800c8e18&gt;] (sys_read+0x44/0x74)
[283986.094931]  r8:00000000 r7:00000003 r6:000003ff r5:7ebe3818 r4:8673bbe0
[283986.094963] [&lt;800c8dd4&gt;] (sys_read+0x0/0x74) from [&lt;800393c0&gt;] (ret_fast_syscall+0x0/0x30)
[283986.094982]  r9:824da000 r8:80039568 r6:7ebe3c8f r5:0000000e r4:7ebe3818
[283986.095011] Code: e3c10d7f e3c0103f e151000c 9afffff6 (e512100c)
[283986.095094] ---[ end trace bc07a2a11408a6af ]---
</code></p>

<h2>分析</h2>

<p>针对上面的dmesg信息进行分析后，得出了如下结论：</p>

<ol>
<li>导致出错的当前(current)进程是<code>pidof</code></li>
<li>pidof程序的原理就是：遍历所有进程的stat(/proc/PID/stat)文件，找出和参数一样的进程ID(pid)。</li>
<li>/proc/PID/stat文件的内容是由<code>do_task_stat</code>(见fs/proc/array.c)函数生成</li>
<li><code>do_task_stat</code>会调用<code>get_wchan</code>(见arch/arm/kernel/process.c)，来获取进程的<a href="http://askubuntu.com/questions/19442/what-is-the-waiting-channel-of-a-process">Waiting Channnel</a></li>
<li><code>get_wchan</code>函数使用<code>unwind_frame</code>(见arch/arm/kernel/stacktrace.c)函数回溯进程的栈指针（fp/sp)，试图获取进程最后一个<code>非调度函数</code>的函数调用</li>
<li><code>unwind_frame</code>却导致了一个内核paging错误</li>
</ol>


<p>根据上面的初步分析，结合我们自己的应用程序，推测造成这个问题的应用层场景如下：
1. 有两个进程p1/busy_worker
2. busy_worker有30多个线程
3. p1不停执行system(pidof(&ldquo;busy_worker&rdquo;))</p>

<p>根据内核打印出来的PC/LR寄存器，可以知道，是unwind_frame函数中出现的内存访问错误：
<code>
[734212.113523] PC is at unwind_frame+0x48/0x68
</code></p>

<p>反汇编内核代码（#号开头的行， 是c语言注释）
```
8003d0d8 &lt;unwind_frame>:
8003d0d8:       e1a0c00d        mov     ip, sp
8003d0dc:       e92dd800        push    {fp, ip, lr, pc}
8003d0e0:       e24cb004        sub     fp, ip, #4</p>

<h1>r1 = frame->sp</h1>

<h1>low = frame->sp;</h1>

<p>8003d0e4:       e5901004        ldr     r1, [r0, #4]</p>

<h1>r3 = r0 = frame</h1>

<p>8003d0e8:       e1a03000        mov     r3, r0</p>

<h1>r2 = unsigned long fp = frame->fp;</h1>

<p>8003d0ec:       e5902000        ldr     r2, [r0]</p>

<h1>r0 = low + 12</h1>

<p>8003d0f0:       e281000c        add     r0, r1, #12</p>

<h1>if (fp &lt; low+12)</h1>

<p>8003d0f4:       e1520000        cmp     r2, r0
8003d0f8:       2a000001        bcs     8003d104 &lt;unwind_frame+0x2c>
8003d0fc:       e3e00015        mvn     r0, #21
8003d100:       e89da800        ldm     sp, {fp, sp, pc}
8003d104:       e2810d7f        add     r0, r1, #8128   ; 0x1fc0
8003d108:       e282c004        add     ip, r2, #4
8003d10c:       e280103f        add     r1, r0, #63     ; 0x3f
8003d110:       e3c10d7f        bic     r0, r1, #8128   ; 0x1fc0
8003d114:       e3c0103f        bic     r1, r0, #63     ; 0x3f
8003d118:       e151000c        cmp     r1, ip
8003d11c:       9afffff6        bls     8003d0fc &lt;unwind_frame+0x24></p>

<h1>r1 = *(r2-12)</h1>

<h1>r1 = *(fp-12)</h1>

<p>8003d120:       e512100c        ldr     r1, [r2, #-12]</p>

<p>8003d124:       e3a00000        mov     r0, #0</p>

<h1>frame->fp = <em>(unsigned long </em>)(fp &ndash; 12);</h1>

<p>8003d128:       e5831000        str     r1, [r3]</p>

<p>8003d12c:       e512c008        ldr     ip, [r2, #-8]
8003d130:       e583c004        str     ip, [r3, #4]
8003d134:       e5122004        ldr     r2, [r2, #-4]
8003d138:       e583200c        str     r2, [r3, #12]
8003d13c:       e89da800        ldm     sp, {fp, sp, pc}
```</p>

<p>反汇编结合内核源代码， 可知出错的时候执行到下面的语句：
```c</p>

<pre><code>/* restore the registers from the stack frame */
frame-&gt;fp = *(unsigned long *)(fp - 12);
</code></pre>

<p><code>
出错时候的平台寄存器如下：
</code>
[734212.113557] pc : [<8003d120>]    lr : [<8003a660>]    psr: a0000013
[734212.113561] sp : 845d1cc8  ip : 00000003  fp : 845d1cd4
[734212.113583] r10: 00000001  r9 : 00000000  r8 : 80493c34
[734212.113597] r7 : 00000000  r6 : 00000000  r5 : 83354960  r4 : 845d1cd8
[734212.113613] r3 : 845d1cd8  r2 : ffffffff  r1 : 80490000  r0 : 8049003f
<code>``
在出现的内存访问错误之前， fp寄存器值已经保存在寄存器r2中了， 对应的值是</code>ffffffff`。
也就是说， 传递给unwind_frame函数的stackframe->fp = 0xffffffff。
出现问题的情况下应用层的用法都是没有问题的，所以这应该是一个内核BUG。
虽然是很清楚导致此内核Bug的原因，但是相关内核函数都没有处理竞争情况，当时就怀疑这个BUG应该和抢占有关系。
由于不太确定，就去Stack Overflow上面问了个问题：
<a href="http://stackoverflow.com/questions/18479894/unwind-frame-cause-a-kernel-paging-error">unwind_frame cause a kernel paging error</a>，不过也一直没有任何有价值的回复。</p>

<h2>巧合</h2>

<p>时隔3个月的后，又想起了这个问题，于是去kernel git上搜索了一番，发现2013年后针对unwind_frame函数的修改挺多。
其中<a href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=1b15ec7a7427d4188ba91b9bbac696250a059d22">Konstantin Khlebnikov提交的一个patch</a>就解决了这个内核Bug。
更巧的是：修改日志中引用了我在Stack Overflow上提的问题。</p>

<h2>Root cause</h2>

<p>Konstantin Khlebnikov在修改日志中写道：</p>

<blockquote><p>get_wchan() is lockless. Task may wakeup at any time and change its own stack, thus each next stack frame may be overwritten and filled with random stuff.
/proc/$pid/stack interface had been disabled for non-current tasks, see [1] But &lsquo;wchan&rsquo; still allows to trigger stack frame unwinding on volatile stack.
This patch fixes oops in unwind_frame() by adding stack pointer validation on each step (as x86 code do), unwind_frame() already checks frame pointer.</p></blockquote>

<p>大意就是：
get_wchan()是没有加锁的，而进程可以在任何时候执行并修改自己的栈，所以进程的栈可能会被修改并填充随机的值。</p>

<p>假设我们的pidof进程PID为100，记做pidof(100)，busy_worker进程PID为99，记做busy_worker(99), 我们碰到的问题就是：
* pidof(100)通过读/proc/99/stat文件触发了内核去获取busy_worker(99)的Waiting Channnel(get_wchan)
* busy_worker(99)执行到获取文件系统信息时候被抢占，此时其调用栈看起来可能是这个样子：
```
main</p>

<pre><code>busy_worker_main
    fun1
        fun2
            fun3
               __kernel_routines_xxxx__
</code></pre>

<p><code>
* get_wchan将busy_worker(99)的fp/sp/lr/pc都保存在stackframe结构体中
</code>c</p>

<pre><code>frame.fp = thread_saved_fp(p);
frame.sp = thread_saved_sp(p);
frame.lr = 0;           /* recovered from the stack */
frame.pc = thread_saved_pc(p);
</code></pre>

<p><code>
* 由于没有锁，此时busy_worker(99)又开始在CPU上执行（抢占），它可能又去执行其他功能代码，调用栈可能是：
</code>
main</p>

<pre><code>busy_worker_main
    fun5
        fun6
            fun7
               __kernel_routines_yyyy__
</code></pre>

<p><code>
* 内核调用unwind_frame开始回溯busy_worker_main(99)的栈。
这个时候问题出现了，此时busy_worker_main(99)的栈已经和第2步中完全不一样了，内核再调用下面语句去访问`上次记录`的栈里面内存，有点类似于访问已经释放了的内存：
</code>c</p>

<pre><code>frame-&gt;fp = *(unsigned long *)(fp - 12);
frame-&gt;sp = *(unsigned long *)(fp - 8);
frame-&gt;pc = *(unsigned long *)(fp - 4);
</code></pre>

<p>```
这个时候，这块内存保存的可能是某个函数的局部变量、或者被push进来的其他寄存器。
总而言之，访问这块内存会得到一个随机值，而这里恰好是0xffffffff，导致了内核访问错误的内存，从而出现paging error.</p>

<h2>参考</h2>

<ul>
<li><a href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=1b15ec7a7427d4188ba91b9bbac696250a059d22">ARM: 7912/1: check stack pointer in get_wchan</a></li>
<li><a href="http://askubuntu.com/questions/19442/what-is-the-waiting-channel-of-a-process">What is the “Waiting Channel” of a process?</a></li>
<li><a href="/images/arm_registers.png">Arm registers</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入分析diskstats]]></title>
    <link href="http://ykrocku.github.io/blog/2014/04/11/diskstats/"/>
    <updated>2014-04-11T09:21:09+08:00</updated>
    <id>http://ykrocku.github.io/blog/2014/04/11/diskstats</id>
    <content type="html"><![CDATA[<h2>背景</h2>

<p>内核很多重要子系统均通过proc文件的方式，将自身的一些统计信息输出，方便最终用户查看各子系统的运行状态，这些统计信息被称为metrics。
直接查看metrics并不能获取到有用的信息，一般都是由特定的应用程序(htop/sar/iostat等)每隔一段时间读取相关metrics，并进行相应计算，给出更具用户可读性的输出。
常见的metrics文件有：</p>

<ul>
<li>cpu调度统计信息的/proc/stat</li>
<li>cpu负载统计信息的/proc/loadavg</li>
</ul>


<p>通用块设备层也有一个重要的统计信息</p>

<ul>
<li>/proc/diskstats
内核通过diskstats文件，将通用块设备层的一些重要指标以文件的形式呈现给用户。</li>
</ul>


<p>因为本文档牵涉到通用块设备层很多细节，建议先了解IO调度器的相关知识。</p>

<h2>初探diskstats</h2>

<p>首先来看下diskstats里面都有些什么，下面截取的是一个diskstats文件内容：
```</p>

<h1>cat /proc/diskstats</h1>

<p>   8       0 sda 8567 1560 140762 3460 0 0 0 0 0 2090 3440
   8       1 sda1 8565 1557 140722 3210 0 0 0 0 0 1840 3190
   8      16 sdb 8157 1970 140762 2940 0 0 0 0 0 1710 2890
   8      17 sdb1 8155 1967 140722 2900 0 0 0 0 0 1670 2850
   8      32 sdc 8920 1574 206410 7870 430 0 461 250 0 6820 8120
   8      33 sdc1 8918 1571 206370 7840 430 0 461 250 0 6790 8090
   8      48 sdd 209703 1628 341966 1318450 3109063 331428 943042901 9728000 0 8943570 11015280
   8      49 sdd1 209701 1625 341926 1318200 3109063 331428 943042901 9728000 0 8943320 11015030
```
虽然如上面提到的，这些数字看上去完全没有规律。不过若想研究内核通用块设备层的统计实现方式，还是得一个一个字段的分析。</p>

<p>简单的说，每一行对应一个块设备，分别有ram0-ram15、loop0-loop7、mtdblock0-mtdblock5，剩下的sdxx就是硬盘和分区了。
这里以sda设备的数据为例，分别列举各字段的意义：
<code>
8       0 sda 8567 1560 140762 3460 0 0 0 0 0 2090 3440
</code></p>

<p>根据内核文档<a href="https://www.kernel.org/doc/Documentation/iostats.txt">iostats.txt</a>中描述，各字段意义如下：</p>

<table>
<thead>
<tr>
<th> 域    </th>
<th> Value  </th>
<th>  Quoted                               </th>
<th>  解释  </th>
</tr>
</thead>
<tbody>
<tr>
<td> F1    </td>
<td> 8      </td>
<td>  major number                         </td>
<td> 此块设备的主设备号 </td>
</tr>
<tr>
<td> F2    </td>
<td> 0      </td>
<td>  minor mumber                         </td>
<td> 此块设备的次设备号 </td>
</tr>
<tr>
<td> F3    </td>
<td> sda    </td>
<td>  device name                          </td>
<td> 此块设备名字 </td>
</tr>
<tr>
<td> F4    </td>
<td> 8567   </td>
<td>  reads completed successfully         </td>
<td> 成功完成的读请求次数 </td>
</tr>
<tr>
<td> F5    </td>
<td> 1560   </td>
<td>  reads merged                         </td>
<td> 读请求的次数 </td>
</tr>
<tr>
<td> F6    </td>
<td> 140762 </td>
<td>  sectors read                         </td>
<td> 读请求的扇区数总和 </td>
</tr>
<tr>
<td> F7    </td>
<td> 3460   </td>
<td>  time spent reading (ms)              </td>
<td> 读请求花费的时间总和 </td>
</tr>
<tr>
<td> F8    </td>
<td> 0      </td>
<td>  writes completed                     </td>
<td> 成功完成的写请求次数 </td>
</tr>
<tr>
<td> F9    </td>
<td> 0      </td>
<td>  writes merged                        </td>
<td> 写请求合并的次数 </td>
</tr>
<tr>
<td>F10    </td>
<td> 0      </td>
<td>  sectors written                      </td>
<td> 写请求的扇区数总和 </td>
</tr>
<tr>
<td>F11    </td>
<td> 0      </td>
<td>  time spent writing (ms)              </td>
<td> 写请求花费的时间总和 </td>
</tr>
<tr>
<td>F12    </td>
<td> 0      </td>
<td>  I/Os currently in progress           </td>
<td> 次块设备队列中的IO请求数 </td>
</tr>
<tr>
<td>F13    </td>
<td> 2090   </td>
<td>  time spent doing I/Os (ms)           </td>
<td> 块设备队列非空时间总和 </td>
</tr>
<tr>
<td>F14    </td>
<td> 3440   </td>
<td>  weighted time spent doing I/Os (ms)  </td>
<td> 块设备队列非空时间加权总和 </td>
</tr>
</tbody>
</table>


<p>基本上都是数量、时间的累加值，按照读、写分开统计。</p>

<h2>流程图</h2>

<p>下图是Linux内核通用块设备层IO请求处理的完整流程，如图例所示，所有的统计相关处理均有用不同颜色标注。
在进行深入分析前，请大致浏览图片，对整个流程有一个大致印象。
<img src="/images/LinuxBlockIO.png" title="[title text [alt text]]" ></p>

<h2>实现分析</h2>

<h3>proc入口</h3>

<p>在内核代码中grep &ldquo;diskstats"即可找到定义在block/genhd.c中的<code>diskstats_show</code>函数。
```c</p>

<pre><code>while ((hd = disk_part_iter_next(&amp;piter))) {
    cpu = part_stat_lock();
    part_round_stats(cpu, hd);
    part_stat_unlock();
    seq_printf(seqf, "%4d %7d %s %lu %lu %llu "
           "%u %lu %lu %llu %u %u %u %u\n",
           MAJOR(part_devt(hd)), MINOR(part_devt(hd)),
           disk_name(gp, hd-&gt;partno, buf),
           part_stat_read(hd, ios[READ]),
           part_stat_read(hd, merges[READ]),
           (unsigned long long)part_stat_read(hd, sectors[READ]),
           jiffies_to_msecs(part_stat_read(hd, ticks[READ])),
           part_stat_read(hd, ios[WRITE]),
           part_stat_read(hd, merges[WRITE]),
           (unsigned long long)part_stat_read(hd, sectors[WRITE]),
           jiffies_to_msecs(part_stat_read(hd, ticks[WRITE])),
           part_in_flight(hd),
           jiffies_to_msecs(part_stat_read(hd, io_ticks)),
           jiffies_to_msecs(part_stat_read(hd, time_in_queue))
        );
</code></pre>

<p>```
此段代码用seq_printf函数将保存在hd_struct结构体内的统计信息组成了diskstats文件。</p>

<h3>数据结构</h3>

<p>用到的数据结构都定义在&lt;linux/genhd.h>中，主要有disk_stats和hd_struct两个结构体，意义见注释：
```c
struct disk_stats {</p>

<pre><code>/*
 *sectors[0] &lt;--&gt; F6 
 *sectors[1] &lt;--&gt; F10
 */
unsigned long sectors[2];    /* READs and WRITEs */

/*
 *ios[0] &lt;--&gt; F4 
 *ios[1] &lt;--&gt; F8
 */
unsigned long ios[2];

/*
 *merges[0] &lt;--&gt; F5 
 *merges[1] &lt;--&gt; F9
 */
unsigned long merges[2];

/*
 *ticks[0] &lt;--&gt; F7 
 *ticks[1] &lt;--&gt; F11
 */
unsigned long ticks[2];

/*F13, time spent doing IOs*/
unsigned long io_ticks;

/*F14, weighted time spent doing I/Os (ms)  */
unsigned long time_in_queue;
</code></pre>

<p>};</p>

<p>struct hd_struct {</p>

<pre><code>unsigned long stamp;

/*F12 I/Os currently in progress*/
atomic_t in_flight[2];

/*如果支持SMP则需要使用“每CPU”变量，否则需要加锁*/
</code></pre>

<h1>ifdef  CONFIG_SMP</h1>

<pre><code>struct disk_stats __percpu *dkstats;
</code></pre>

<h1>else</h1>

<pre><code>struct disk_stats dkstats;
</code></pre>

<h1>endif</h1>

<pre><code>atomic_t ref;
struct rcu_head rcu_head;
</code></pre>

<p>};
```</p>

<h3>F7/F11 ticks</h3>

<p>见下一节</p>

<h3>F4/F8 ios</h3>

<p>如流程图所示，在每个IO结束后，都会调用blk_account_io_done函数，来对完成的IO进行统计。
blk_account_io_done统计了 <code>ios(F4/F8)</code>和<code>ticks(F7/F11)</code>，还处理了<code>in_flight</code>（后续节有分析）。
```c
static void blk_account_io_done(struct request *req)
{</p>

<pre><code>/*
 * 不统计Flush请求，见 http://en.wikipedia.org/wiki/Disk_buffer#Cache_flushing
 */
if (blk_do_io_stat(req) &amp;&amp; !(req-&gt;cmd_flags &amp; REQ_FLUSH_SEQ)) {
    /*
     * duration是当前时间（IO完成时间）减去此IO的入队时间（见流程图）
     */
    unsigned long duration = jiffies - req-&gt;start_time;

    /*从req获取请求类型：R / W*/
    const int rw = rq_data_dir(req);
    struct hd_struct *part;
    int cpu;

    cpu = part_stat_lock();
    /*获取请求对应的partition(part)*/
    part = req-&gt;part;
    /*
     * 该partition的ios[rw]加1
     * part_stat_inc定义在&lt;linux/genhd.h&gt;中
     * part_stat_inc这个宏用来处理SMP和非SMP的细节，见上面的结构体定义
     */
    part_stat_inc(cpu, part, ios[rw]);

    /*
     * 将此IO的存活时间加进ticks
     */
    part_stat_add(cpu, part, ticks[rw], duration);

    part_round_stats(cpu, part);

    /*
     *完成了一个IO，也就是in_flight（正在进行）的IO少了一个
     */
    part_dec_in_flight(part, rw);

    hd_struct_put(part);
    part_stat_unlock();
}
</code></pre>

<p>}
```</p>

<h3>F5/F9 merges</h3>

<p>内核每执行一次Back Merge或Front Merge，都会调用drive_stat_acct。
其实in_flight也是在这个函数中统计的，<code>new_io</code>参数用来区分是新的IO，如果不是新IO则是在merge的时候调用的：
```c
static void drive_stat_acct(struct request *rq, int new_io)
{</p>

<pre><code>struct hd_struct *part;
/*从req获取请求类型：R / W*/
int rw = rq_data_dir(rq);
int cpu;

if (!blk_do_io_stat(rq))
    return;

cpu = part_stat_lock();

if (!new_io) {
    part = rq-&gt;part;
    /*
     * 非新IO，merges[rw]加1
     */
    part_stat_inc(cpu, part, merges[rw]);
} else {
    .....
    part_round_stats(cpu, part);
    /*
     * 新提交了一个IO，也就是in_flight（正在进行）的IO多了一个
     */
    part_inc_in_flight(part, rw);
}

part_stat_unlock();
</code></pre>

<p>}
```</p>

<h3>F6/F10 sectors</h3>

<p>读写扇区总数是在blk_account_io_completion函数中统计的，如流程图中所示，这个函数在每次IO结束后调用：
```c
static void blk_account_io_completion(struct request *req, unsigned int bytes)
{</p>

<pre><code>if (blk_do_io_stat(req)) {
    const int rw = rq_data_dir(req);
    struct hd_struct *part;
    int cpu;

    cpu = part_stat_lock();
    part = req-&gt;part;
    /*
     *bytes是此IO请求的数据长度，右移9位等同于除以512，即转换成扇区数
     *然后加到sectors[rw]中
     */
    part_stat_add(cpu, part, sectors[rw], bytes &gt;&gt; 9);
    part_stat_unlock();
}
</code></pre>

<p>}
```</p>

<h3>F12 in_flight</h3>

<p>in_flight这个统计比较特别，因为其他统计都是计算累加值，而它是记录当前队列中IO请求的个数。统计方法则是：</p>

<ul>
<li>新IO请求插入队列（被merge的不算）后加1</li>
<li>完成一个IO后减1
实现见上面章节中的blk_account_io_done和drive_stat_acct函数内的注释。</li>
</ul>


<h3>F14 time_in_queue</h3>

<p>见下一节。</p>

<h3>F13 io_ticks</h3>

<p>io_ticks统计块设备请求队列非空的总时间，统计时间点与in_flight相同，统计代码实现在part_round_stats_single函数中：
```c
static void part_round_stats_single(int cpu, struct hd_struct *part,</p>

<pre><code>                unsigned long now)
</code></pre>

<p>{</p>

<pre><code>if (now == part-&gt;stamp)
    return;
/*
 *块设备队列非空
 */
if (part_in_flight(part)) {
    /*
     *统计加权时间 队列中IO请求个数 * 耗费时间
     */
    __part_stat_add(cpu, part, time_in_queue,
            part_in_flight(part) * (now - part-&gt;stamp));

    /*
     *统计队列非空时间
     */
    __part_stat_add(cpu, part, io_ticks, (now - part-&gt;stamp));
}
part-&gt;stamp = now;
</code></pre>

<p>}
```</p>

<p>整个代码实现的逻辑比较简单，在新IO请求插入队列（被merge不算），或完成一个IO请求的时候均执行如下操作：</p>

<ul>
<li><p>队列为空</p>

<ol>
<li>记下时间stamp = t1</li>
</ol>
</li>
<li><p>队列不为空</p>

<ol>
<li>io_ticks[rw]  += t2-t1</li>
<li>time_in_queue += in_flight * (t2-t1)</li>
<li>记下时间stamp = t2</li>
</ol>
</li>
</ul>


<p>下面是一个实际的例子，示例io_ticks和time_in_queue的计算过程：</p>

<table>
<thead>
<tr>
<th>  ID     </th>
<th>  Time       </th>
<th>   Ops             </th>
<th>  in_flight    </th>
<th>    stamp     </th>
<th>   gap     </th>
<th>  io_ticks   </th>
<th> time_in_queue    </th>
</tr>
</thead>
<tbody>
<tr>
<td>   0     </td>
<td>   100.00    </td>
<td> 新IO请求入队      </td>
<td>   0           </td>
<td>     0        </td>
<td>    &mdash;&ndash;    </td>
<td>   0         </td>
<td>  0               </td>
</tr>
<tr>
<td>   1     </td>
<td>   100.10    </td>
<td> 新IO请求入队      </td>
<td>   1           </td>
<td>     100.00   </td>
<td>    0.10   </td>
<td>   0.10      </td>
<td>  0.10            </td>
</tr>
<tr>
<td>   3     </td>
<td>   101.20    </td>
<td> 完成一个IO请求    </td>
<td>   2           </td>
<td>     100.10   </td>
<td>    0.80   </td>
<td>   1.20      </td>
<td>  1.70            </td>
</tr>
<tr>
<td>   4     </td>
<td>   103.50    </td>
<td> 完成一个IO请求    </td>
<td>   1           </td>
<td>     100.20   </td>
<td>    1.30   </td>
<td>   2.50      </td>
<td>  3.00            </td>
</tr>
<tr>
<td>   5     </td>
<td>   153.50    </td>
<td> 新IO请求入队      </td>
<td>   0           </td>
<td>     103.50   </td>
<td>    &mdash;&ndash;    </td>
<td>   2.50      </td>
<td>  3.00            </td>
</tr>
<tr>
<td>   6     </td>
<td>   154.50    </td>
<td> 完成一个IO请求    </td>
<td>   1           </td>
<td>     153.50   </td>
<td>    1.00   </td>
<td>   3.50      </td>
<td>  4.00            </td>
</tr>
</tbody>
</table>


<p>总共时间 54.50s， IO队列非空时间3.50s</p>
]]></content>
  </entry>
  
</feed>
